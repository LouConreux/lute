<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        <link rel="canonical" href="http://127.0.0.1:8000/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/tasks/sfx_find_peaks/">
        <link rel="shortcut icon" href="../../../../../../../../../../../img/favicon.ico">
        <title>Sfx find peaks - LUTE</title>
        <link href="../../../../../../../../../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../../../../../../../../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../../../../../../../../../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css">
        <link href="../../../../../../../../../../../assets/_mkdocstrings.css" rel="stylesheet">

        <script src="../../../../../../../../../../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../../../../../../../../../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../../../../../../../../../../..">LUTE</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../../../../../../../../../../../usage/" class="nav-link">Setup</a>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">/ <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Home</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Dorlhiac</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Documentos</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">SLAC</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">DataProjects</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Repos</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">My lute</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Docs</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Source</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/managed_tasks/" class="dropdown-item">Managed tasks</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Execution</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/execution/debug_utils/" class="dropdown-item">Debug utils</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/execution/executor/" class="dropdown-item">Executor</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/execution/ipc/" class="dropdown-item">Ipc</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Io</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/io/_sqlite/" class="dropdown-item"> sqlite</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/io/config/" class="dropdown-item">Config</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/io/db/" class="dropdown-item">Db</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/io/elog/" class="dropdown-item">Elog</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/io/exceptions/" class="dropdown-item">Exceptions</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Models</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/io/models/base/" class="dropdown-item">Base</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/io/models/sfx_find_peaks/" class="dropdown-item">Sfx find peaks</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/io/models/sfx_index/" class="dropdown-item">Sfx index</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/io/models/sfx_merge/" class="dropdown-item">Sfx merge</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/io/models/sfx_solve/" class="dropdown-item">Sfx solve</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/io/models/smd/" class="dropdown-item">Smd</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/io/models/tests/" class="dropdown-item">Tests</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Tasks</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/tasks/dataclasses/" class="dropdown-item">Dataclasses</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/tasks/sfx_find_peaks/" class="dropdown-item active">Sfx find peaks</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/tasks/sfx_index/" class="dropdown-item">Sfx index</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/tasks/smalldata/" class="dropdown-item">Smalldata</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/tasks/task/" class="dropdown-item">Task</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/tasks/tasklets/" class="dropdown-item">Tasklets</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/tasks/test/" class="dropdown-item">Test</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/tasks/xas/" class="dropdown-item">Xas</a>
</li>
            
<li>
    <a href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/tasks/xss/" class="dropdown-item">Xss</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
    </ul>
  </li>
    </ul>
  </li>
    </ul>
  </li>
    </ul>
  </li>
    </ul>
  </li>
    </ul>
  </li>
    </ul>
  </li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Adrs <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../../../../../../../../../adrs/" class="dropdown-item">Architecture Decision Records</a>
</li>
                                    
<li>
    <a href="../../../../../../../../../../../adrs/MADR_LICENSE/" class="dropdown-item">MADR LICENSE</a>
</li>
                                    
<li>
    <a href="../../../../../../../../../../../adrs/adr-1/" class="dropdown-item">[ADR-1] All Analysis Tasks Inherit from a Base Class</a>
</li>
                                    
<li>
    <a href="../../../../../../../../../../../adrs/adr-2/" class="dropdown-item">[ADR-2] Analysis Task Submission and Communication is Performed Via Executors</a>
</li>
                                    
<li>
    <a href="../../../../../../../../../../../adrs/adr-3/" class="dropdown-item">[ADR-3] `Executor`s will run all `Task`s via subprocess</a>
</li>
                                    
<li>
    <a href="../../../../../../../../../../../adrs/adr-4/" class="dropdown-item">[ADR-4] Airflow `Operator`s and LUTE `Executor`s are Separate Entities</a>
</li>
                                    
<li>
    <a href="../../../../../../../../../../../adrs/adr-5/" class="dropdown-item">[ADR-5] Task-Executor IPC is Managed by Communicator Objects</a>
</li>
                                    
<li>
    <a href="../../../../../../../../../../../adrs/adr-6/" class="dropdown-item">[ADR-6] Third-party Config Files Managed by Templates Rendered by `ThirdPartyTask`s</a>
</li>
                                    
<li>
    <a href="../../../../../../../../../../../adrs/adr-7/" class="dropdown-item">[ADR-7] `Task` Configuration is Stored in a Database Managed by `Executor`s</a>
</li>
                                    
<li>
    <a href="../../../../../../../../../../../adrs/adr-8/" class="dropdown-item">[ADR-8] Airflow credentials/authorization requires special launch program</a>
</li>
                                    
<li>
    <a href="../../../../../../../../../../../adrs/adr-9/" class="dropdown-item">[ADR-9] Airflow launch script will run as long lived batch job.</a>
</li>
                                    
<li>
    <a href="../../../../../../../../../../../adrs/madr_template/" class="dropdown-item">Madr template</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Design <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../../../../../../../../../design/database/" class="dropdown-item">LUTE Configuration Database Specification</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Docs <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../../../../../../../../../docs/SUMMARY/" class="dropdown-item">SUMMARY</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Source <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../../../../../../../../../source/managed_tasks/" class="dropdown-item">Managed tasks</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Execution</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../../../../../../../../../source/execution/debug_utils/" class="dropdown-item">Debug utils</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/execution/executor/" class="dropdown-item">Executor</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/execution/ipc/" class="dropdown-item">Ipc</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Io</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../../../../../../../../../source/io/_sqlite/" class="dropdown-item"> sqlite</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/io/config/" class="dropdown-item">Config</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/io/db/" class="dropdown-item">Db</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/io/elog/" class="dropdown-item">Elog</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/io/exceptions/" class="dropdown-item">Exceptions</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Models</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../../../../../../../../../source/io/models/base/" class="dropdown-item">Base</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/io/models/sfx_find_peaks/" class="dropdown-item">Sfx find peaks</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/io/models/sfx_index/" class="dropdown-item">Sfx index</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/io/models/sfx_merge/" class="dropdown-item">Sfx merge</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/io/models/sfx_solve/" class="dropdown-item">Sfx solve</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/io/models/smd/" class="dropdown-item">Smd</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/io/models/tests/" class="dropdown-item">Tests</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Tasks</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../../../../../../../../../source/tasks/dataclasses/" class="dropdown-item">Dataclasses</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/tasks/sfx_find_peaks/" class="dropdown-item">Sfx find peaks</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/tasks/sfx_index/" class="dropdown-item">Sfx index</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/tasks/smalldata/" class="dropdown-item">Smalldata</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/tasks/task/" class="dropdown-item">Task</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/tasks/tasklets/" class="dropdown-item">Tasklets</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/tasks/test/" class="dropdown-item">Test</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/tasks/xas/" class="dropdown-item">Xas</a>
</li>
            
<li>
    <a href="../../../../../../../../../../../source/tasks/xss/" class="dropdown-item">Xss</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Tutorial <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../../../../../../../../../tutorial/creating_workflows/" class="dropdown-item">Workflows with Airflow</a>
</li>
                                    
<li>
    <a href="../../../../../../../../../../../tutorial/new_task/" class="dropdown-item">Integrating a New `Task`</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/tasks/dataclasses/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="/home/dorlhiac/Documentos/SLAC/DataProjects/Repos/my_lute/docs/source/tasks/sfx_index/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="2"><a href="#tasks.sfx_find_peaks" class="nav-link">sfx_find_peaks</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#tasks.sfx_find_peaks.CxiWriter" class="nav-link">CxiWriter</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#tasks.sfx_find_peaks.FindPeaksPyAlgos" class="nav-link">FindPeaksPyAlgos</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#tasks.sfx_find_peaks.add_peaks_to_libpressio_configuration" class="nav-link">add_peaks_to_libpressio_configuration</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#tasks.sfx_find_peaks.generate_libpressio_configuration" class="nav-link">generate_libpressio_configuration</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#tasks.sfx_find_peaks.write_master_file" class="nav-link">write_master_file</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<div class="doc doc-object doc-module">



<a id="tasks.sfx_find_peaks"></a>
    <div class="doc doc-contents first">

      <p>Classes for peak finding tasks in SFX.</p>


<p><span class="doc-section-title">Classes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="tasks.sfx_find_peaks.CxiWriter" href="../../../../../../../../../../../../source/tasks/sfx_find_peaks/#tasks.sfx_find_peaks.CxiWriter">CxiWriter</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>utility class for writing peak finding results to CXI files.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="tasks.sfx_find_peaks.FindPeaksPyAlgos" href="../../../../../../../../../../../../source/tasks/sfx_find_peaks/#tasks.sfx_find_peaks.FindPeaksPyAlgos">FindPeaksPyAlgos</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>peak finding using psana's PyAlgos algorithm. Optional data
compression and decompression with libpressio for data reduction tests.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="tasks.sfx_find_peaks.CxiWriter" class="doc doc-heading">
            <code>CxiWriter</code>


</h2>


    <div class="doc doc-contents ">


              <details class="quote">
                <summary>Source code in <code>lute/tasks/sfx_find_peaks.py</code></summary>
                <pre class="highlight"><code class="language-python">class CxiWriter:

    def __init__(
        self,
        outdir: str,
        rank: int,
        exp: str,
        run: int,
        n_events: int,
        det_shape: Tuple[int, ...],
        min_peaks: int,
        max_peaks: int,
        i_x: Any,  # Not typed becomes it comes from psana
        i_y: Any,  # Not typed becomes it comes from psana
        ipx: Any,  # Not typed becomes it comes from psana
        ipy: Any,  # Not typed becomes it comes from psana
        tag: str,
    ):
        """
        Set up the CXI files to which peak finding results will be saved.

        Parameters:

            outdir (str): Output directory for cxi file.

            rank (int): MPI rank of the caller.

            exp (str): Experiment string.

            run (int): Experimental run.

            n_events (int): Number of events to process.

            det_shape (Tuple[int, int]): Shape of the numpy array storing the detector
                data. This must be aCheetah-stile 2D array.

            min_peaks (int): Minimum number of peaks per image.

            max_peaks (int): Maximum number of peaks per image.

            i_x (Any): Array of pixel indexes along x

            i_y (Any): Array of pixel indexes along y

            ipx (Any): Pixel indexes with respect to detector origin (x component)

            ipy (Any): Pixel indexes with respect to detector origin (y component)

            tag (str): Tag to append to cxi file names.
        """
        self._det_shape: Tuple[int, ...] = det_shape
        self._i_x: Any = i_x
        self._i_y: Any = i_y
        self._ipx: Any = ipx
        self._ipy: Any = ipy
        self._index: int = 0

        # Create and open the HDF5 file
        fname: str = f"{exp}_r{run:0&gt;4}_{rank}{tag}.cxi"
        Path(outdir).mkdir(exist_ok=True)
        self._outh5: Any = h5py.File(Path(outdir) / fname, "w")

        # Entry_1 entry for processing with CrystFEL
        entry_1: Any = self._outh5.create_group("entry_1")
        keys: List[str] = [
            "nPeaks",
            "peakXPosRaw",
            "peakYPosRaw",
            "rcent",
            "ccent",
            "rmin",
            "rmax",
            "cmin",
            "cmax",
            "peakTotalIntensity",
            "peakMaxIntensity",
            "peakRadius",
        ]
        ds_expId: Any = entry_1.create_dataset(
            "experimental_identifier", (n_events,), maxshape=(None,), dtype=int
        )
        ds_expId.attrs["axes"] = "experiment_identifier"
        data_1: Any = entry_1.create_dataset(
            "/entry_1/data_1/data",
            (n_events, det_shape[0], det_shape[1]),
            chunks=(1, det_shape[0], det_shape[1]),
            maxshape=(None, det_shape[0], det_shape[1]),
            dtype=numpy.float32,
        )
        data_1.attrs["axes"] = "experiment_identifier"
        key: str
        for key in ["powderHits", "powderMisses", "mask"]:
            entry_1.create_dataset(
                f"/entry_1/data_1/{key}",
                (det_shape[0], det_shape[1]),
                chunks=(det_shape[0], det_shape[1]),
                maxshape=(det_shape[0], det_shape[1]),
                dtype=float,
            )

        # Peak-related entries
        for key in keys:
            if key == "nPeaks":
                ds_x: Any = self._outh5.create_dataset(
                    f"/entry_1/result_1/{key}",
                    (n_events,),
                    maxshape=(None,),
                    dtype=int,
                )
                ds_x.attrs["minPeaks"] = min_peaks
                ds_x.attrs["maxPeaks"] = max_peaks
            else:
                ds_x: Any = self._outh5.create_dataset(
                    f"/entry_1/result_1/{key}",
                    (n_events, max_peaks),
                    maxshape=(None, max_peaks),
                    chunks=(1, max_peaks),
                    dtype=float,
                )
            ds_x.attrs["axes"] = "experiment_identifier:peaks"

        # Timestamp entries
        lcls_1: Any = self._outh5.create_group("LCLS")
        keys: List[str] = [
            "eventNumber",
            "machineTime",
            "machineTimeNanoSeconds",
            "fiducial",
            "photon_energy_eV",
        ]
        key: str
        for key in keys:
            if key == "photon_energy_eV":
                ds_x: Any = lcls_1.create_dataset(
                    f"{key}", (n_events,), maxshape=(None,), dtype=float
                )
            else:
                ds_x = lcls_1.create_dataset(
                    f"{key}", (n_events,), maxshape=(None,), dtype=int
                )
            ds_x.attrs["axes"] = "experiment_identifier"

        ds_x = self._outh5.create_dataset(
            "/LCLS/detector_1/EncoderValue", (n_events,), maxshape=(None,), dtype=float
        )
        ds_x.attrs["axes"] = "experiment_identifier"

    def write_event(
        self,
        img: NDArray[numpy.float_],
        peaks: Any,  # Not typed becomes it comes from psana
        timestamp_seconds: int,
        timestamp_nanoseconds: int,
        timestamp_fiducials: int,
        photon_energy: float,
    ):
        """
        Write peak finding results for an event into the HDF5 file.

        Parameters:

            img (NDArray[numpy.float_]): Detector data for the event

            peaks: (Any): Peak information for the event, as recovered from the PyAlgos
                algorithm

            timestamp_seconds (int): Second part of the event's timestamp information

            timestamp_nanoseconds (int): Nanosecond part of the event's timestamp
                information

            timestamp_fiducials (int): Fiducials part of the event's timestamp
                information

            photon_energy (float): Photon energy for the event
        """
        ch_rows: NDArray[numpy.float_] = peaks[:, 0] * self._det_shape[1] + peaks[:, 1]
        ch_cols: NDArray[numpy.float_] = peaks[:, 2]

        # Entry_1 entry for processing with CrystFEL
        self._outh5["/entry_1/data_1/data"][self._index, :, :] = img.reshape(
            -1, img.shape[-1]
        )
        self._outh5["/entry_1/result_1/nPeaks"][self._index] = peaks.shape[0]
        self._outh5["/entry_1/result_1/peakXPosRaw"][self._index, : peaks.shape[0]] = (
            ch_cols.astype("int")
        )
        self._outh5["/entry_1/result_1/peakYPosRaw"][self._index, : peaks.shape[0]] = (
            ch_rows.astype("int")
        )
        self._outh5["/entry_1/result_1/rcent"][self._index, : peaks.shape[0]] = peaks[
            :, 6
        ]
        self._outh5["/entry_1/result_1/ccent"][self._index, : peaks.shape[0]] = peaks[
            :, 7
        ]
        self._outh5["/entry_1/result_1/rmin"][self._index, : peaks.shape[0]] = peaks[
            :, 10
        ]
        self._outh5["/entry_1/result_1/rmax"][self._index, : peaks.shape[0]] = peaks[
            :, 11
        ]
        self._outh5["/entry_1/result_1/cmin"][self._index, : peaks.shape[0]] = peaks[
            :, 12
        ]
        self._outh5["/entry_1/result_1/cmax"][self._index, : peaks.shape[0]] = peaks[
            :, 13
        ]
        self._outh5["/entry_1/result_1/peakTotalIntensity"][
            self._index, : peaks.shape[0]
        ] = peaks[:, 5]
        self._outh5["/entry_1/result_1/peakMaxIntensity"][
            self._index, : peaks.shape[0]
        ] = peaks[:, 4]

        # Calculate and write pixel radius
        peaks_cenx: NDArray[numpy.float_] = (
            self._i_x[
                numpy.array(peaks[:, 0], dtype=numpy.int64),
                numpy.array(peaks[:, 1], dtype=numpy.int64),
                numpy.array(peaks[:, 2], dtype=numpy.int64),
            ]
            + 0.5
            - self._ipx
        )
        peaks_ceny: NDArray[numpy.float_] = (
            self._i_y[
                numpy.array(peaks[:, 0], dtype=numpy.int64),
                numpy.array(peaks[:, 1], dtype=numpy.int64),
                numpy.array(peaks[:, 2], dtype=numpy.int64),
            ]
            + 0.5
            - self._ipy
        )
        peak_radius: NDArray[numpy.float_] = numpy.sqrt(
            (peaks_cenx**2) + (peaks_ceny**2)
        )
        self._outh5["/entry_1/result_1/peakRadius"][
            self._index, : peaks.shape[0]
        ] = peak_radius

        # LCLS entry dataset
        self._outh5["/LCLS/machineTime"][self._index] = timestamp_seconds
        self._outh5["/LCLS/machineTimeNanoSeconds"][self._index] = timestamp_nanoseconds
        self._outh5["/LCLS/fiducial"][self._index] = timestamp_fiducials
        self._outh5["/LCLS/photon_energy_eV"][self._index] = photon_energy

        self._index += 1

    def write_non_event_data(
        self,
        powder_hits: NDArray[numpy.float_],
        powder_misses: NDArray[numpy.float_],
        mask: NDArray[numpy.uint16],
        clen: float,
    ):
        """
        Write to the file data that is not related to a specific event (masks, powders)

        Parameters:

            powder_hits (NDArray[numpy.float_]): Virtual powder pattern from hits

            powder_misses (NDArray[numpy.float_]): Virtual powder pattern from hits

            mask: (NDArray[numpy.uint16]): Pixel ask to write into the file

        """
        # Add powders and mask to files, reshaping them to match the crystfel
        # convention
        self._outh5["/entry_1/data_1/powderHits"][:] = powder_hits.reshape(
            -1, powder_hits.shape[-1]
        )
        self._outh5["/entry_1/data_1/powderMisses"][:] = powder_misses.reshape(
            -1, powder_misses.shape[-1]
        )
        self._outh5["/entry_1/data_1/mask"][:] = (1 - mask).reshape(
            -1, mask.shape[-1]
        )  # Crystfel expects inverted values

        # Add clen distance
        self._outh5["/LCLS/detector_1/EncoderValue"][:] = clen

    def optimize_and_close_file(
        self,
        num_hits: int,
        max_peaks: int,
    ):
        """
        Resize data blocks and write additional information to the file

        Parameters:

            num_hits (int): Number of hits for which information has been saved to the
                file

            max_peaks (int): Maximum number of peaks (per event) for which information
                can be written into the file
        """

        # Resize the entry_1 entry
        data_shape: Tuple[int, ...] = self._outh5["/entry_1/data_1/data"].shape
        self._outh5["/entry_1/data_1/data"].resize(
            (num_hits, data_shape[1], data_shape[2])
        )
        self._outh5[f"/entry_1/result_1/nPeaks"].resize((num_hits,))
        key: str
        for key in [
            "peakXPosRaw",
            "peakYPosRaw",
            "rcent",
            "ccent",
            "rmin",
            "rmax",
            "cmin",
            "cmax",
            "peakTotalIntensity",
            "peakMaxIntensity",
            "peakRadius",
        ]:
            self._outh5[f"/entry_1/result_1/{key}"].resize((num_hits, max_peaks))

        # Resize LCLS entry
        for key in [
            "eventNumber",
            "machineTime",
            "machineTimeNanoSeconds",
            "fiducial",
            "detector_1/EncoderValue",
            "photon_energy_eV",
        ]:
            self._outh5[f"/LCLS/{key}"].resize((num_hits,))
        self._outh5.close()</code></pre>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="tasks.sfx_find_peaks.CxiWriter.__init__" class="doc doc-heading">
            <code class="highlight language-python">__init__(outdir, rank, exp, run, n_events, det_shape, min_peaks, max_peaks, i_x, i_y, ipx, ipy, tag)</code>

</h3>


    <div class="doc doc-contents ">

      <p>Set up the CXI files to which peak finding results will be saved.</p>
<p>Parameters:</p>
<pre><code>outdir (str): Output directory for cxi file.

rank (int): MPI rank of the caller.

exp (str): Experiment string.

run (int): Experimental run.

n_events (int): Number of events to process.

det_shape (Tuple[int, int]): Shape of the numpy array storing the detector
    data. This must be aCheetah-stile 2D array.

min_peaks (int): Minimum number of peaks per image.

max_peaks (int): Maximum number of peaks per image.

i_x (Any): Array of pixel indexes along x

i_y (Any): Array of pixel indexes along y

ipx (Any): Pixel indexes with respect to detector origin (x component)

ipy (Any): Pixel indexes with respect to detector origin (y component)

tag (str): Tag to append to cxi file names.
</code></pre>

            <details class="quote">
              <summary>Source code in <code>lute/tasks/sfx_find_peaks.py</code></summary>
              <pre class="highlight"><code class="language-python">def __init__(
    self,
    outdir: str,
    rank: int,
    exp: str,
    run: int,
    n_events: int,
    det_shape: Tuple[int, ...],
    min_peaks: int,
    max_peaks: int,
    i_x: Any,  # Not typed becomes it comes from psana
    i_y: Any,  # Not typed becomes it comes from psana
    ipx: Any,  # Not typed becomes it comes from psana
    ipy: Any,  # Not typed becomes it comes from psana
    tag: str,
):
    """
    Set up the CXI files to which peak finding results will be saved.

    Parameters:

        outdir (str): Output directory for cxi file.

        rank (int): MPI rank of the caller.

        exp (str): Experiment string.

        run (int): Experimental run.

        n_events (int): Number of events to process.

        det_shape (Tuple[int, int]): Shape of the numpy array storing the detector
            data. This must be aCheetah-stile 2D array.

        min_peaks (int): Minimum number of peaks per image.

        max_peaks (int): Maximum number of peaks per image.

        i_x (Any): Array of pixel indexes along x

        i_y (Any): Array of pixel indexes along y

        ipx (Any): Pixel indexes with respect to detector origin (x component)

        ipy (Any): Pixel indexes with respect to detector origin (y component)

        tag (str): Tag to append to cxi file names.
    """
    self._det_shape: Tuple[int, ...] = det_shape
    self._i_x: Any = i_x
    self._i_y: Any = i_y
    self._ipx: Any = ipx
    self._ipy: Any = ipy
    self._index: int = 0

    # Create and open the HDF5 file
    fname: str = f"{exp}_r{run:0&gt;4}_{rank}{tag}.cxi"
    Path(outdir).mkdir(exist_ok=True)
    self._outh5: Any = h5py.File(Path(outdir) / fname, "w")

    # Entry_1 entry for processing with CrystFEL
    entry_1: Any = self._outh5.create_group("entry_1")
    keys: List[str] = [
        "nPeaks",
        "peakXPosRaw",
        "peakYPosRaw",
        "rcent",
        "ccent",
        "rmin",
        "rmax",
        "cmin",
        "cmax",
        "peakTotalIntensity",
        "peakMaxIntensity",
        "peakRadius",
    ]
    ds_expId: Any = entry_1.create_dataset(
        "experimental_identifier", (n_events,), maxshape=(None,), dtype=int
    )
    ds_expId.attrs["axes"] = "experiment_identifier"
    data_1: Any = entry_1.create_dataset(
        "/entry_1/data_1/data",
        (n_events, det_shape[0], det_shape[1]),
        chunks=(1, det_shape[0], det_shape[1]),
        maxshape=(None, det_shape[0], det_shape[1]),
        dtype=numpy.float32,
    )
    data_1.attrs["axes"] = "experiment_identifier"
    key: str
    for key in ["powderHits", "powderMisses", "mask"]:
        entry_1.create_dataset(
            f"/entry_1/data_1/{key}",
            (det_shape[0], det_shape[1]),
            chunks=(det_shape[0], det_shape[1]),
            maxshape=(det_shape[0], det_shape[1]),
            dtype=float,
        )

    # Peak-related entries
    for key in keys:
        if key == "nPeaks":
            ds_x: Any = self._outh5.create_dataset(
                f"/entry_1/result_1/{key}",
                (n_events,),
                maxshape=(None,),
                dtype=int,
            )
            ds_x.attrs["minPeaks"] = min_peaks
            ds_x.attrs["maxPeaks"] = max_peaks
        else:
            ds_x: Any = self._outh5.create_dataset(
                f"/entry_1/result_1/{key}",
                (n_events, max_peaks),
                maxshape=(None, max_peaks),
                chunks=(1, max_peaks),
                dtype=float,
            )
        ds_x.attrs["axes"] = "experiment_identifier:peaks"

    # Timestamp entries
    lcls_1: Any = self._outh5.create_group("LCLS")
    keys: List[str] = [
        "eventNumber",
        "machineTime",
        "machineTimeNanoSeconds",
        "fiducial",
        "photon_energy_eV",
    ]
    key: str
    for key in keys:
        if key == "photon_energy_eV":
            ds_x: Any = lcls_1.create_dataset(
                f"{key}", (n_events,), maxshape=(None,), dtype=float
            )
        else:
            ds_x = lcls_1.create_dataset(
                f"{key}", (n_events,), maxshape=(None,), dtype=int
            )
        ds_x.attrs["axes"] = "experiment_identifier"

    ds_x = self._outh5.create_dataset(
        "/LCLS/detector_1/EncoderValue", (n_events,), maxshape=(None,), dtype=float
    )
    ds_x.attrs["axes"] = "experiment_identifier"</code></pre>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tasks.sfx_find_peaks.CxiWriter.optimize_and_close_file" class="doc doc-heading">
            <code class="highlight language-python">optimize_and_close_file(num_hits, max_peaks)</code>

</h3>


    <div class="doc doc-contents ">

      <p>Resize data blocks and write additional information to the file</p>
<p>Parameters:</p>
<pre><code>num_hits (int): Number of hits for which information has been saved to the
    file

max_peaks (int): Maximum number of peaks (per event) for which information
    can be written into the file
</code></pre>

            <details class="quote">
              <summary>Source code in <code>lute/tasks/sfx_find_peaks.py</code></summary>
              <pre class="highlight"><code class="language-python">def optimize_and_close_file(
    self,
    num_hits: int,
    max_peaks: int,
):
    """
    Resize data blocks and write additional information to the file

    Parameters:

        num_hits (int): Number of hits for which information has been saved to the
            file

        max_peaks (int): Maximum number of peaks (per event) for which information
            can be written into the file
    """

    # Resize the entry_1 entry
    data_shape: Tuple[int, ...] = self._outh5["/entry_1/data_1/data"].shape
    self._outh5["/entry_1/data_1/data"].resize(
        (num_hits, data_shape[1], data_shape[2])
    )
    self._outh5[f"/entry_1/result_1/nPeaks"].resize((num_hits,))
    key: str
    for key in [
        "peakXPosRaw",
        "peakYPosRaw",
        "rcent",
        "ccent",
        "rmin",
        "rmax",
        "cmin",
        "cmax",
        "peakTotalIntensity",
        "peakMaxIntensity",
        "peakRadius",
    ]:
        self._outh5[f"/entry_1/result_1/{key}"].resize((num_hits, max_peaks))

    # Resize LCLS entry
    for key in [
        "eventNumber",
        "machineTime",
        "machineTimeNanoSeconds",
        "fiducial",
        "detector_1/EncoderValue",
        "photon_energy_eV",
    ]:
        self._outh5[f"/LCLS/{key}"].resize((num_hits,))
    self._outh5.close()</code></pre>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tasks.sfx_find_peaks.CxiWriter.write_event" class="doc doc-heading">
            <code class="highlight language-python">write_event(img, peaks, timestamp_seconds, timestamp_nanoseconds, timestamp_fiducials, photon_energy)</code>

</h3>


    <div class="doc doc-contents ">

      <p>Write peak finding results for an event into the HDF5 file.</p>
<p>Parameters:</p>
<pre><code>img (NDArray[numpy.float_]): Detector data for the event

peaks: (Any): Peak information for the event, as recovered from the PyAlgos
    algorithm

timestamp_seconds (int): Second part of the event's timestamp information

timestamp_nanoseconds (int): Nanosecond part of the event's timestamp
    information

timestamp_fiducials (int): Fiducials part of the event's timestamp
    information

photon_energy (float): Photon energy for the event
</code></pre>

            <details class="quote">
              <summary>Source code in <code>lute/tasks/sfx_find_peaks.py</code></summary>
              <pre class="highlight"><code class="language-python">def write_event(
    self,
    img: NDArray[numpy.float_],
    peaks: Any,  # Not typed becomes it comes from psana
    timestamp_seconds: int,
    timestamp_nanoseconds: int,
    timestamp_fiducials: int,
    photon_energy: float,
):
    """
    Write peak finding results for an event into the HDF5 file.

    Parameters:

        img (NDArray[numpy.float_]): Detector data for the event

        peaks: (Any): Peak information for the event, as recovered from the PyAlgos
            algorithm

        timestamp_seconds (int): Second part of the event's timestamp information

        timestamp_nanoseconds (int): Nanosecond part of the event's timestamp
            information

        timestamp_fiducials (int): Fiducials part of the event's timestamp
            information

        photon_energy (float): Photon energy for the event
    """
    ch_rows: NDArray[numpy.float_] = peaks[:, 0] * self._det_shape[1] + peaks[:, 1]
    ch_cols: NDArray[numpy.float_] = peaks[:, 2]

    # Entry_1 entry for processing with CrystFEL
    self._outh5["/entry_1/data_1/data"][self._index, :, :] = img.reshape(
        -1, img.shape[-1]
    )
    self._outh5["/entry_1/result_1/nPeaks"][self._index] = peaks.shape[0]
    self._outh5["/entry_1/result_1/peakXPosRaw"][self._index, : peaks.shape[0]] = (
        ch_cols.astype("int")
    )
    self._outh5["/entry_1/result_1/peakYPosRaw"][self._index, : peaks.shape[0]] = (
        ch_rows.astype("int")
    )
    self._outh5["/entry_1/result_1/rcent"][self._index, : peaks.shape[0]] = peaks[
        :, 6
    ]
    self._outh5["/entry_1/result_1/ccent"][self._index, : peaks.shape[0]] = peaks[
        :, 7
    ]
    self._outh5["/entry_1/result_1/rmin"][self._index, : peaks.shape[0]] = peaks[
        :, 10
    ]
    self._outh5["/entry_1/result_1/rmax"][self._index, : peaks.shape[0]] = peaks[
        :, 11
    ]
    self._outh5["/entry_1/result_1/cmin"][self._index, : peaks.shape[0]] = peaks[
        :, 12
    ]
    self._outh5["/entry_1/result_1/cmax"][self._index, : peaks.shape[0]] = peaks[
        :, 13
    ]
    self._outh5["/entry_1/result_1/peakTotalIntensity"][
        self._index, : peaks.shape[0]
    ] = peaks[:, 5]
    self._outh5["/entry_1/result_1/peakMaxIntensity"][
        self._index, : peaks.shape[0]
    ] = peaks[:, 4]

    # Calculate and write pixel radius
    peaks_cenx: NDArray[numpy.float_] = (
        self._i_x[
            numpy.array(peaks[:, 0], dtype=numpy.int64),
            numpy.array(peaks[:, 1], dtype=numpy.int64),
            numpy.array(peaks[:, 2], dtype=numpy.int64),
        ]
        + 0.5
        - self._ipx
    )
    peaks_ceny: NDArray[numpy.float_] = (
        self._i_y[
            numpy.array(peaks[:, 0], dtype=numpy.int64),
            numpy.array(peaks[:, 1], dtype=numpy.int64),
            numpy.array(peaks[:, 2], dtype=numpy.int64),
        ]
        + 0.5
        - self._ipy
    )
    peak_radius: NDArray[numpy.float_] = numpy.sqrt(
        (peaks_cenx**2) + (peaks_ceny**2)
    )
    self._outh5["/entry_1/result_1/peakRadius"][
        self._index, : peaks.shape[0]
    ] = peak_radius

    # LCLS entry dataset
    self._outh5["/LCLS/machineTime"][self._index] = timestamp_seconds
    self._outh5["/LCLS/machineTimeNanoSeconds"][self._index] = timestamp_nanoseconds
    self._outh5["/LCLS/fiducial"][self._index] = timestamp_fiducials
    self._outh5["/LCLS/photon_energy_eV"][self._index] = photon_energy

    self._index += 1</code></pre>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tasks.sfx_find_peaks.CxiWriter.write_non_event_data" class="doc doc-heading">
            <code class="highlight language-python">write_non_event_data(powder_hits, powder_misses, mask, clen)</code>

</h3>


    <div class="doc doc-contents ">

      <p>Write to the file data that is not related to a specific event (masks, powders)</p>
<p>Parameters:</p>
<pre><code>powder_hits (NDArray[numpy.float_]): Virtual powder pattern from hits

powder_misses (NDArray[numpy.float_]): Virtual powder pattern from hits

mask: (NDArray[numpy.uint16]): Pixel ask to write into the file
</code></pre>

            <details class="quote">
              <summary>Source code in <code>lute/tasks/sfx_find_peaks.py</code></summary>
              <pre class="highlight"><code class="language-python">def write_non_event_data(
    self,
    powder_hits: NDArray[numpy.float_],
    powder_misses: NDArray[numpy.float_],
    mask: NDArray[numpy.uint16],
    clen: float,
):
    """
    Write to the file data that is not related to a specific event (masks, powders)

    Parameters:

        powder_hits (NDArray[numpy.float_]): Virtual powder pattern from hits

        powder_misses (NDArray[numpy.float_]): Virtual powder pattern from hits

        mask: (NDArray[numpy.uint16]): Pixel ask to write into the file

    """
    # Add powders and mask to files, reshaping them to match the crystfel
    # convention
    self._outh5["/entry_1/data_1/powderHits"][:] = powder_hits.reshape(
        -1, powder_hits.shape[-1]
    )
    self._outh5["/entry_1/data_1/powderMisses"][:] = powder_misses.reshape(
        -1, powder_misses.shape[-1]
    )
    self._outh5["/entry_1/data_1/mask"][:] = (1 - mask).reshape(
        -1, mask.shape[-1]
    )  # Crystfel expects inverted values

    # Add clen distance
    self._outh5["/LCLS/detector_1/EncoderValue"][:] = clen</code></pre>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="tasks.sfx_find_peaks.FindPeaksPyAlgos" class="doc doc-heading">
            <code>FindPeaksPyAlgos</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="tasks.task.Task" href="../../../../../../../../../../../../source/tasks/task/#tasks.task.Task">Task</a></code></p>


      <p>Task that performs peak finding using the PyAlgos peak finding algorithms and
writes the peak information to CXI files.</p>

              <details class="quote">
                <summary>Source code in <code>lute/tasks/sfx_find_peaks.py</code></summary>
                <pre class="highlight"><code class="language-python">class FindPeaksPyAlgos(Task):
    """
    Task that performs peak finding using the PyAlgos peak finding algorithms and
    writes the peak information to CXI files.
    """

    def __init__(self, *, params: TaskParameters) -&gt; None:
        super().__init__(params=params)

    def _run(self) -&gt; None:
        ds: Any = MPIDataSource(
            f"exp={self._task_parameters.lute_config.experiment}:"
            f"run={self._task_parameters.lute_config.run}:smd"
        )
        if self._task_parameters.n_events != 0:
            ds.break_after(self._task_parameters.n_events)

        det: Any = Detector(self._task_parameters.det_name)
        det.do_reshape_2d_to_3d(flag=True)

        evr: Any = Detector(self._task_parameters.event_receiver)

        i_x: Any = det.indexes_x(self._task_parameters.lute_config.run).astype(
            numpy.int64
        )
        i_y: Any = det.indexes_y(self._task_parameters.lute_config.run).astype(
            numpy.int64
        )
        ipx: Any
        ipy: Any
        ipx, ipy = det.point_indexes(
            self._task_parameters.lute_config.run, pxy_um=(0, 0)
        )

        alg: Any = None
        num_hits: int = 0
        num_events: int = 0
        num_empty_images: int = 0
        tag: str = self._task_parameters.tag
        if (tag != "") and (tag[0] != "_"):
            tag = "_" + tag

        evt: Any
        for evt in ds.events():

            evt_id: Any = evt.get(EventId)
            timestamp_seconds: int = evt_id.time()[0]
            timestamp_nanoseconds: int = evt_id.time()[1]
            timestamp_fiducials: int = evt_id.fiducials()
            event_codes: Any = evr.eventCodes(evt)

            if isinstance(self._task_parameters.pv_camera_length, float):
                clen: float = self._task_parameters.pv_camera_length
            else:
                clen = (
                    ds.env().epicsStore().value(self._task_parameters.pv_camera_length)
                )

            if self._task_parameters.event_logic:
                if not self._task_parameters.event_code in event_codes:
                    continue

            img: Any = det.calib(evt)

            if img is None:
                num_empty_images += 1
                continue

            if alg is None:
                det_shape: Tuple[int, ...] = img.shape
                if len(det_shape) == 3:
                    det_shape = (det_shape[0] * det_shape[1], det_shape[2])
                else:
                    det_shape = img.shape

                mask: NDArray[numpy.uint16] = numpy.ones(det_shape).astype(numpy.uint16)

                if self._task_parameters.psana_mask:
                    mask = det.mask(
                        self.task_parameters.run,
                        calib=False,
                        status=True,
                        edges=False,
                        centra=False,
                        unbond=False,
                        unbondnbrs=False,
                    ).astype(numpy.uint16)

                hdffh: Any
                if self._task_parameters.mask_file is not None:
                    with h5py.File(self._task_parameters.mask_file, "r") as hdffh:
                        loaded_mask: NDArray[numpy.int] = hdffh["entry_1/data_1/mask"][
                            :
                        ]
                        mask *= loaded_mask.astype(numpy.uint16)

                file_writer: CxiWriter = CxiWriter(
                    outdir=self._task_parameters.outdir,
                    rank=ds.rank,
                    exp=self._task_parameters.lute_config.experiment,
                    run=self._task_parameters.lute_config.run,
                    n_events=self._task_parameters.n_events,
                    det_shape=det_shape,
                    i_x=i_x,
                    i_y=i_y,
                    ipx=ipx,
                    ipy=ipy,
                    min_peaks=self._task_parameters.min_peaks,
                    max_peaks=self._task_parameters.max_peaks,
                    tag=tag,
                )
                alg: Any = PyAlgos(mask=mask, pbits=0)  # pbits controls verbosity
                alg.set_peak_selection_pars(
                    npix_min=self._task_parameters.npix_min,
                    npix_max=self._task_parameters.npix_max,
                    amax_thr=self._task_parameters.amax_thr,
                    atot_thr=self._task_parameters.atot_thr,
                    son_min=self._task_parameters.son_min,
                )

                if self._task_parameters.compression is not None:

                    libpressio_config = generate_libpressio_configuration(
                        compressor=self._task_parameters.compression.compressor,
                        roi_window_size=self._task_parameters.compression.roi_window_size,
                        bin_size=self._task_parameters.compression.bin_size,
                        abs_error=self._task_parameters.compression.abs_error,
                        libpressio_mask=mask,
                    )

                powder_hits: NDArray[numpy.float_] = numpy.zeros(det_shape)
                powder_misses: NDArray[numpy.float_] = numpy.zeros(det_shape)

            peaks: Any = alg.peak_finder_v3r3(
                img,
                rank=self._task_parameters.peak_rank,
                r0=self._task_parameters.r0,
                dr=self._task_parameters.dr,
                #      nsigm=self._task_parameters.nsigm,
            )

            num_events += 1

            if (peaks.shape[0] &gt;= self._task_parameters.min_peaks) and (
                peaks.shape[0] &lt;= self._task_parameters.max_peaks
            ):

                if self._task_parameters.compression is not None:

                    libpressio_config_with_peaks = (
                        add_peaks_to_libpressio_configuration(libpressio_config, peaks)
                    )
                    compressor = PressioCompressor.from_config(
                        libpressio_config_with_peaks
                    )
                    compressed_img = compressor.encode(img)
                    decompressed_img = numpy.zeros_like(img)
                    decompressed = compressor.decode(compressed_img, decompressed_img)
                    img = decompressed_img

                try:
                    photon_energy: float = (
                        Detector("EBeam").get(evt).ebeamPhotonEnergy()
                    )
                except AttributeError:
                    photon_energy = (
                        1.23984197386209e-06
                        / ds.env().epicsStore().value("SIOC:SYS0:ML00:AO192")
                        / 1.0e9
                    )

                file_writer.write_event(
                    img=img,
                    peaks=peaks,
                    timestamp_seconds=timestamp_seconds,
                    timestamp_nanoseconds=timestamp_nanoseconds,
                    timestamp_fiducials=timestamp_fiducials,
                    photon_energy=photon_energy,
                )
                num_hits += 1

            # TODO: Fix bug here
            # generate / update powders
            if peaks.shape[0] &gt;= self._task_parameters.min_peaks:
                powder_hits = numpy.maximum(powder_hits, img)
            else:
                powder_misses = numpy.maximum(powder_misses, img)

        if num_empty_images != 0:
            msg: Message = Message(
                contents=f"Rank {ds.rank} encountered {num_empty_images} empty images."
            )
            self._report_to_executor(msg)

        file_writer.write_non_event_data(
            powder_hits=powder_hits,
            powder_misses=powder_misses,
            mask=mask,
            clen=clen,
        )

        file_writer.optimize_and_close_file(
            num_hits=num_hits, max_peaks=self._task_parameters.max_peaks
        )

        COMM_WORLD.Barrier()

        num_hits_per_rank: List[int] = COMM_WORLD.gather(num_hits, root=0)
        num_hits_total: int = COMM_WORLD.reduce(num_hits, SUM)
        num_events_per_rank: List[int] = COMM_WORLD.gather(num_events, root=0)

        if ds.rank == 0:
            master_fname: Path = write_master_file(
                mpi_size=ds.size,
                outdir=self._task_parameters.outdir,
                exp=self._task_parameters.lute_config.experiment,
                run=self._task_parameters.lute_config.run,
                tag=tag,
                n_hits_per_rank=num_hits_per_rank,
                n_hits_total=num_hits_total,
            )

            # Write final summary file
            f: TextIO
            with open(
                Path(self._task_parameters.outdir) / f"peakfinding{tag}.summary", "w"
            ) as f:
                print(f"Number of events processed: {num_events_per_rank[-1]}", file=f)
                print(f"Number of hits found: {num_hits_total}", file=f)
                print(
                    "Fractional hit rate: "
                    f"{(num_hits_total/num_events_per_rank[-1]):.2f}",
                    file=f,
                )
                print(f"No. hits per rank: {num_hits_per_rank}", file=f)

            with open(Path(self._task_parameters.out_file), "w") as f:
                print(f"{master_fname}", file=f)

            # Write out_file

    def _post_run(self) -&gt; None:
        super()._post_run()
        self._result.task_status = TaskStatus.COMPLETED</code></pre>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h2 id="tasks.sfx_find_peaks.add_peaks_to_libpressio_configuration" class="doc doc-heading">
            <code class="highlight language-python">add_peaks_to_libpressio_configuration(lp_json, peaks)</code>

</h2>


    <div class="doc doc-contents ">

      <p>Add peak infromation to libpressio configuration</p>
<p>Parameters:</p>
<pre><code>lp_json: Dictionary storing the configuration JSON structure for the libpressio
    library.

peaks (Any): Peak information as returned by psana.
</code></pre>
<p>Returns:</p>
<pre><code>lp_json: Updated configuration JSON structure for the libpressio library.
</code></pre>

            <details class="quote">
              <summary>Source code in <code>lute/tasks/sfx_find_peaks.py</code></summary>
              <pre class="highlight"><code class="language-python">def add_peaks_to_libpressio_configuration(lp_json, peaks) -&gt; Dict[str, Any]:
    """
    Add peak infromation to libpressio configuration

    Parameters:

        lp_json: Dictionary storing the configuration JSON structure for the libpressio
            library.

        peaks (Any): Peak information as returned by psana.

    Returns:

        lp_json: Updated configuration JSON structure for the libpressio library.
    """
    lp_json["compressor_config"]["pressio"]["roibin"]["roibin:centers"] = (
        numpy.ascontiguousarray(numpy.uint64(peaks[:, [2, 1, 0]]))
    )
    return lp_json</code></pre>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="tasks.sfx_find_peaks.generate_libpressio_configuration" class="doc doc-heading">
            <code class="highlight language-python">generate_libpressio_configuration(compressor, roi_window_size, bin_size, abs_error, libpressio_mask)</code>

</h2>


    <div class="doc doc-contents ">

      <p>Create the configuration JSON for the libpressio library</p>
<p>Parameters:</p>
<pre><code>compressor (Literal["sz3", "qoz"]): Compression algorithm to use
    ("qoz" or "sz3").

abs_error (float): Bound value for the absolute error.

bin_size (int): Bining Size.

roi_window_size (int): Default size of the ROI window.

libpressio_mask (NDArray): mask to be applied to the data.
</code></pre>
<p>Returns:</p>
<pre><code>lp_json (Dict[str, Any]): Dictionary storing the JSON configuration structure
for the libpressio library
</code></pre>

            <details class="quote">
              <summary>Source code in <code>lute/tasks/sfx_find_peaks.py</code></summary>
              <pre class="highlight"><code class="language-python">def generate_libpressio_configuration(
    compressor: Literal["sz3", "qoz"],
    roi_window_size: int,
    bin_size: int,
    abs_error: float,
    libpressio_mask,
) -&gt; Dict[str, Any]:
    """
    Create the configuration JSON for the libpressio library

    Parameters:

        compressor (Literal["sz3", "qoz"]): Compression algorithm to use
            ("qoz" or "sz3").

        abs_error (float): Bound value for the absolute error.

        bin_size (int): Bining Size.

        roi_window_size (int): Default size of the ROI window.

        libpressio_mask (NDArray): mask to be applied to the data.

    Returns:

        lp_json (Dict[str, Any]): Dictionary storing the JSON configuration structure
        for the libpressio library
    """

    if compressor == "qoz":
        pressio_opts: Dict[str, Any] = {
            "pressio:abs": abs_error,
            "qoz": {"qoz:stride": 8},
        }
    elif compressor == "sz3":
        pressio_opts = {"pressio:abs": abs_error}

    lp_json = {
        "compressor_id": "pressio",
        "early_config": {
            "pressio": {
                "pressio:compressor": "roibin",
                "roibin": {
                    "roibin:metric": "composite",
                    "roibin:background": "mask_binning",
                    "roibin:roi": "fpzip",
                    "background": {
                        "binning:compressor": "pressio",
                        "mask_binning:compressor": "pressio",
                        "pressio": {"pressio:compressor": compressor},
                    },
                    "composite": {
                        "composite:plugins": [
                            "size",
                            "time",
                            "input_stats",
                            "error_stat",
                        ]
                    },
                },
            }
        },
        "compressor_config": {
            "pressio": {
                "roibin": {
                    "roibin:roi_size": [roi_window_size, roi_window_size, 0],
                    "roibin:centers": None,  # "roibin:roi_strategy": "coordinates",
                    "roibin:nthreads": 4,
                    "roi": {"fpzip:prec": 0},
                    "background": {
                        "mask_binning:mask": None,
                        "mask_binning:shape": [bin_size, bin_size, 1],
                        "mask_binning:nthreads": 4,
                        "pressio": pressio_opts,
                    },
                }
            }
        },
        "name": "pressio",
    }

    lp_json["compressor_config"]["pressio"]["roibin"]["background"][
        "mask_binning:mask"
    ] = (1 - libpressio_mask)

    return lp_json</code></pre>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="tasks.sfx_find_peaks.write_master_file" class="doc doc-heading">
            <code class="highlight language-python">write_master_file(mpi_size, outdir, exp, run, tag, n_hits_per_rank, n_hits_total)</code>

</h2>


    <div class="doc doc-contents ">

      <p>Generate a virtual dataset to map all individual files for this run.</p>
<p>Parameters:</p>
<pre><code>mpi_size (int): Number of ranks in the MPI pool.

outdir (str): Output directory for cxi file.

exp (str): Experiment string.

run (int): Experimental run.

tag (str): Tag to append to cxi file names.

n_hits_per_rank (List[int]): Array containing the number of hits found on each
    node processing data.

n_hits_total (int): Total number of hits found across all nodes.
</code></pre>
<p>Returns:</p>
<pre><code>The path to the the written master file
</code></pre>

            <details class="quote">
              <summary>Source code in <code>lute/tasks/sfx_find_peaks.py</code></summary>
              <pre class="highlight"><code class="language-python">def write_master_file(
    mpi_size: int,
    outdir: str,
    exp: str,
    run: int,
    tag: str,
    n_hits_per_rank: List[int],
    n_hits_total: int,
) -&gt; Path:
    """
    Generate a virtual dataset to map all individual files for this run.

    Parameters:

        mpi_size (int): Number of ranks in the MPI pool.

        outdir (str): Output directory for cxi file.

        exp (str): Experiment string.

        run (int): Experimental run.

        tag (str): Tag to append to cxi file names.

        n_hits_per_rank (List[int]): Array containing the number of hits found on each
            node processing data.

        n_hits_total (int): Total number of hits found across all nodes.

    Returns:

        The path to the the written master file
    """
    # Retrieve paths to the files containing data
    fnames: List[Path] = []
    fi: int
    for fi in range(mpi_size):
        if n_hits_per_rank[fi] &gt; 0:
            fnames.append(Path(outdir) / f"{exp}_r{run:0&gt;4}_{fi}{tag}.cxi")
    if len(fnames) == 0:
        sys.exit("No hits found")

    # Retrieve list of entries to populate in the virtual hdf5 file
    dname_list, key_list, shape_list, dtype_list = [], [], [], []
    datasets = ["/entry_1/result_1", "/LCLS/detector_1", "/LCLS", "/entry_1/data_1"]
    f = h5py.File(fnames[0], "r")
    for dname in datasets:
        dset = f[dname]
        for key in dset.keys():
            if f"{dname}/{key}" not in datasets:
                dname_list.append(dname)
                key_list.append(key)
                shape_list.append(dset[key].shape)
                dtype_list.append(dset[key].dtype)
    f.close()

    # Compute cumulative powder hits and misses for all files
    powder_hits, powder_misses = None, None
    for fn in fnames:
        f = h5py.File(fn, "r")
        if powder_hits is None:
            powder_hits = f["entry_1/data_1/powderHits"][:].copy()
            powder_misses = f["entry_1/data_1/powderMisses"][:].copy()
        else:
            powder_hits = numpy.maximum(
                powder_hits, f["entry_1/data_1/powderHits"][:].copy()
            )
            powder_misses = numpy.maximum(
                powder_misses, f["entry_1/data_1/powderMisses"][:].copy()
            )
        f.close()

    vfname: Path = Path(outdir) / f"{exp}_r{run:0&gt;4}{tag}.cxi"
    with h5py.File(vfname, "w") as vdf:

        # Write the virtual hdf5 file
        for dnum in range(len(dname_list)):
            dname = f"{dname_list[dnum]}/{key_list[dnum]}"
            if key_list[dnum] not in ["mask", "powderHits", "powderMisses"]:
                layout = h5py.VirtualLayout(
                    shape=(n_hits_total,) + shape_list[dnum][1:], dtype=dtype_list[dnum]
                )
                cursor = 0
                for i, fn in enumerate(fnames):
                    vsrc = h5py.VirtualSource(
                        fn, dname, shape=(n_hits_per_rank[i],) + shape_list[dnum][1:]
                    )
                    if len(shape_list[dnum]) == 1:
                        layout[cursor : cursor + n_hits_per_rank[i]] = vsrc
                    else:
                        layout[cursor : cursor + n_hits_per_rank[i], :] = vsrc
                    cursor += n_hits_per_rank[i]
                vdf.create_virtual_dataset(dname, layout, fillvalue=-1)

        vdf["entry_1/data_1/powderHits"] = powder_hits
        vdf["entry_1/data_1/powderMisses"] = powder_misses

    return vfname</code></pre>
            </details>
    </div>

</div>



  </div>

    </div>

</div></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../../../../../../../../../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../../../../../../../../../js/base.js" defer></script>
        <script src="../../../../../../../../../../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
